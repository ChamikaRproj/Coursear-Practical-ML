---
title: "Practical-ML-Project"
author: "Chamika Senanayake"
date: "10/3/2020"
output:
  pdf_document: default
  html_document: default
---


## Loading of required libraries

````{r}
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(corrplot)
library(gbm)
````

## Dowanloading Reading Data files

### Downloading Script
```{r}
if(!file.exists("pml-training.csv"))
{
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "pml-training.csv", method = 'curl')
}
dataset <- read.csv("pml-training.csv", na.strings = c("NA", ""))
if(!file.exists("pml-testing.csv"))
{
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "pml-testing.csv", method = 'curl')
}
validation <- read.csv("pml-testing.csv")
```

### Data Loading Script
````{r}
train_in <- read.csv('./pml-training.csv', header=T)
valid_in <- read.csv('./pml-testing.csv', header=T)
````

## Basic Data Exploration, Cleaning, Preprocessing
````{r}
dim(train_in)
dim(valid_in)
````

NA removal
````{r}
trainData<- train_in[, colSums(is.na(train_in)) == 0]
validData <- valid_in[, colSums(is.na(valid_in)) == 0]
dim(trainData)
dim(validData)
````

removal of 1st 7 variables that are less usefull on classe
````{r}
trainData <- trainData[, -c(1:7)]
validData <- validData[, -c(1:7)]
dim(trainData)
dim(validData)
````

Preparation of dataset for prediction by dividiong into 70% as traindata and 30% test dataset

````{r}
set.seed(1234) 
inTrain <- createDataPartition(trainData$classe, p = 0.7, list = FALSE)
trainData <- trainData[inTrain, ]
testData <- trainData[-inTrain, ]
dim(trainData)
dim(testData)
````

Nero-Zero-Variance removal

````{r}
NZV <- nearZeroVar(trainData)
trainData <- trainData[, -NZV]
testData  <- testData[, -NZV]
dim(trainData)
dim(testData)
````

correlation plot uses the following parameters for abstract visualization

````{r}
cor_mat <- cor(trainData[, -53])
corrplot(cor_mat, order = "FPC", method = "color", type = "upper", tl.cex = 0.8, tl.col = rgb(0, 0, 0))
````

Identification of names of the variables

````{r}
highlyCorrelated = findCorrelation(cor_mat, cutoff=0.75)
names(trainData)[highlyCorrelated]
````

## ML Model build

the dataset will be trained andpredicted using following algorithms

1. Classification trees (CT)
2. Random forests (RF)
3. Generalized Boosted Model (GBM)

### 1. Classification trees (CT)


classification tree dendogram is plotted using fancyRpartPlot() function
````{r}
set.seed(12345)
decisionTreeMod1 <- rpart(classe ~ ., data=trainData, method="class")
fancyRpartPlot(decisionTreeMod1)
````

validation of the model “decisionTreeModel” on the testData to visualize and generate pro matrix results as below

````{r}
testData$classe<-as.factor(testData$classe)
predictTreeMod1 <- predict(decisionTreeMod1, testData, type = "class")
cmtree <- confusionMatrix(predictTreeMod1, testData$classe)
cmtree

# plot matrix results
plot(cmtree$table, col = cmtree$byClass, 
     main = paste("Decision Tree - Accuracy =", round(cmtree$overall['Accuracy'], 4)))
````

thus illustrates accuracy rate of ***`r round(cmtree$overall['Accuracy'], 4)`**

### 2. Random forests (RF)

as done in CT model we validate the RF1 model and generate a confusionMatrix as following
````{r}
controlRF <- trainControl(method="cv", number=3, verboseIter=FALSE)
modRF1 <- train(classe ~ ., data=trainData, method="rf", trControl=controlRF)
modRF1$finalModel

predictRF1 <- predict(modRF1, newdata=testData)
cmrf <- confusionMatrix(predictRF1, testData$classe)
cmrf
```

the model is plotted as following 

````{r}
plot(modRF1)

plot(cmrf$table, col = cmrf$byClass, main = paste("Random Forest Confusion Matrix: Accuracy =", round(cmrf$overall['Accuracy'], 4)))
````



### 3. Generalized Boosted Model (GBM)

formulation of the model is done by
````{r}
set.seed(12345)
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
modGBM  <- train(classe ~ ., data=trainData, method = "gbm", trControl = controlGBM, verbose = FALSE)
modGBM$finalModel
````

````{r}
print(modGBM)
````

Validation
````{r}
predictGBM <- predict(modGBM, newdata=testData)
cmGBM <- confusionMatrix(predictGBM, testData$classe)
cmGBM
````

Using RF method the accuracy is high

## best model application for data validation

````{r}
Results <- predict(modRF1, newdata=validData)
Results
````

